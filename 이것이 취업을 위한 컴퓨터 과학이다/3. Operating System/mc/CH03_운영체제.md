# CH02. 컴퓨터 구조

- [운영체제의 큰 그림](#1-운영체제의-큰-그림)
- [프로세스와 스레드](#2-프로세스와-스레드)
- [동기화와 교착 상태](#3-동기화와-교착-상태)
- [CPU 스케줄링](#4-cpu-스케줄링)
- [가상 메모리](#5-가상-메모리)
- [파일 시스템](#6-파일-시스템)
- [추가 정리](#추가-정리)

## :pushpin: 핵심 개념 요약

## 1. 운영체제의 큰 그림

### 간단한 용어 정리

- `자원(시스템 자원, (system) resource)` : 프로그램 실행에 필요한 요소  
   실행에 필요한 ‘데이터(소프트웨어)’, 실행에 필요한 ‘부품(하드웨어)’
- `운영 체제(Operating System, OS)` : 응용프로그램 또는 사용자가 컴퓨터 하드웨어를 편리하고 효율적으로 사용하게 하기 위하여 시스템 자원(메모리, 프로세서 등)을 관리하고 여러가지 프로그램이 필요로 하는 공통적인 서비스를 제공하는 소프트웨어

- `프로세스(process)` : 실행 중인 프로그램의 인스턴스(instance)  
   => 하드디스크 등에 저장되어 있는 프로그램을 사용하기 위해 메모리에 복사한다.

- `스레드(thread)` : 프로세스 내에서 실행되는 가장 작은 실행 단위. 동일한 프로세스의 자원을 공유한다.

### 운영체제란?

- 운영 체제의 핵심 기능은  
   (1) 자원 할당 및 관리  
   (2) 프로세스 및 스레드 관리

### 운영체제의 역할

- `CPU 스케줄링` : CPU의 한정된 자원을 실행중인 프로그램들이 공정하고 합리적으로 할당받을 수 있도록 운영체제가 CPU의 할당 순서와 사용 시간을 결정한다.

- `메모리 관리` : 프로그램을 메모리에 적재 및 삭제하며 효율적으로 관리  
   가상 메모리 기술(실제 물리적인 메모리 크기보다 더 큰 메모리를 이용)을 활용

- `파일/디렉터리 관리` : 보조기억장치에서 원하는 정보 빠르게 접근하기 위해 `파일 시스템`을 활용해 보조기억장치 내의 정보들을 효율적으로 관리  
  (`파일 시스템` : 보조기억장치 내의 정보를 파일 및 폴더(디렉터리) 단위로 접근·관리할 수 있도록 만드는 운영체제 내부 프로그램)

- `입출력장치 및 캐시 메모리 관리` : 일부 입출력장치의 장치 드라이버, 하드웨어
  인터럽트 서비스 루틴을 제공하거나 캐시 메모리의 일관성을 유지하는 등의 기능을 제공

- `프로세스 및 스레드 관리` : 메모리에 적재된 여러 프로세스에 필요한 자원을 할당하고, 스레드는 할당받은 자원을 바탕으로 작업 수행. 프로세스를 이루는 스레드가 둘 이상인 경우에는 동일한 작
  업을 동시 진행 가능
  운영체제는 프로세스와 스레드가 올바르게 처리되도록 실행의 순
  서 제어, 자원을 적절하게 배분

<div align="center">
   <img src="./assets/운영체제 큰 그림.PNG" style="height:360px">
</div>

### 시스템 콜과 이중 모드

- `커널 영역(kernel space)` : 메모리 내에서 운영체제가 적재되는 영역
- `사용자 영역(user space)` : 운영체제가 적재되는 커널 영역 외에 사용자 응용 프로그램이 적재되는 공간
- `시스템 콜(system call)` : 운영체제의 서비스를 제공받기 위한 수단(인터페이스)으로, 호출 가능한 함수의 형태를 가진다.

일반적으로 (사용자)응용 프로그램은 CPU, 메모리와 같은 자원에 직접 접근 또는 조작이 불가능하기 때문에, `시스템 콜(system call)`을 호출하여 운영체제 코드를 실행한다.  
`(= 운영체제가 자신의 코드를 실행한 응용 프로그램의 자원 접근 및 조작을 대행)`

운영체제마다 제공하는 시스템 콜의 종류와 개수는 다양하다.

<div align="center" style="margin:40px">
   <img src="./assets/시스템 콜.PNG" style="height:360px">
</div>

> 프로세스는 또 다른 프로세스를 생성하며 계층적 구조로 관리된다. 이때 새 프로세스를 생성한 프로세스를 `부모 프로세스(parent process)`, 부모 프로세스에 의해 생성된 프로세스를 `자식 프로세스(child process)`라고 한다.

### 시스템 콜 호출 과정

- `소프트웨어 인터럽트(software interrupt)` : 명령어에 의해 발생하는 인터럽트

(1) 사용자 영역을 실행하는 과정에서 시스템 콜이 호출  
(2) CPU는 현재 수행 중인 작업을 백업  
(3) 커널 영역 내의 인터럽트를 처리하기 위한 코드(시스템 콜을 구성하는 코드)를 실행한 뒤  
(4) 다시 사용자 영역의 코드 실행을 재개

// 여기에서 만약에 자원을 리턴하게 된다면?
OS는 프로세스에 가장 주소를 리턴한다.

운영체제는 대부분 “자체 자원 그 자체”를 주는 게 아니라,
“그 자원을 가리키거나 간접적으로 조작할 수 있는 핸들 또는 주소”를 리턴합니다.

메모리 관련 요청 → 보통 가상 주소 리턴

파일, 소켓, 프로세스 등 → 보통 핸들(정수 ID) 리턴

```

 전체 흐름 요약
사용자 프로그램(스레드)이 어떤 자원이 필요함

예: 메모리 할당, 파일 열기, 네트워크 접속 등

운영체제에게 요청하기 위해 시스템 콜(System Call)을 사용

사용자 모드(User Mode)에서 커널 모드(Kernel Mode)로 전환됨

운영체제가 요청 처리 → 자원 할당 or 작업 수행

예: 메모리 공간을 확보하고 주소 리턴, 파일 핸들을 생성하여 리턴 등

결과(또는 자원 핸들)를 사용자 프로그램으로 리턴

다시 커널 모드에서 사용자 모드로 전환됨

스레드는 리턴받은 자원을 이용해 계속 작업 수행

예: 리턴받은 주소에 데이터를 저장하거나, 파일 핸들을 사용해 파일에 쓰기 등
```

## 2. 프로세스와 스레드

- `포그라운드 프로세스(foreground process)` : 사용자가 보는 공간에서 사용자와 상호작용

- `백그라운드 프로세스(background process)` : 사용자가 보지 못하는 공간
  - `데몬(demon) == 서비스(service)` : 사용자와 상호 작용 X

### 프로세스와 메모리

`사용자 영역`

- 정적 할당 영역 (실행도중 크기 변동 X)
  - `코드 영역`  
    : 실행 가능한 명령어가 저장되는 공간, 읽기 전용(read-only, 쓰기 금지)
  - `데이터 영역`  
    : 프로그램이 실행되는 동안 유지할 데이터가 저장되는 공간(정적 변수, 전역 변수)
- 동적 할당 영역 (실행도중 크기 변동 O)
  - `힙 영역`  
    : 사용자가 직접 할당 가능한 저장 공간 (메모리 누수(memory leak) 발생 가능하여 가비지 컬렉션(garbage collection) 기능 제공하기도 함)
  - `스택 영역`  
    : 일시적으로 사용할 값들이 저장되는 공간 (매개변수, 지역 변수, 함수 복귀 주소)
    `스택 트레이스(stack trace)`(특정 시점에 스택 영역에 저장된 함수 호출 정보)가 저장될 수 있다

`커널 영역`

- `PCB(프로세스 제어 블록,Process Control Block)`
  - 프로세스와 관련한 다양한 정보를 내포하는 구조체의 일종
  - 프로세스 ID(PID), 실행 과정에서 사용한 레지스터 값, 프로세스 상태, 프로세스가 언제, CPU 스케줄링(우선순위) 정보, 메모리 관련 정보, 프로세스가 사용한 파일 및 입출력장치 관련 정보가 명시된다.
  - 여러 PCB들은 커널 내에 `프로세스 테이블(process table)`의 형태로 관리
  - 프로그램 실행시 PCB가 프로세스 테이블에 추가, 종료 시 제거  
    \*\* `좀비 프로세스(zombie process)` : 프로세스가 비정상 종료되어 사용한 자원이 회수되었음에도 프로세스 테이블에 남아있는 비정상 종료 상태

### 타이머 인터럽트

- 다양한 프로세스들은 한정된 시간 동안 운영체제로부터 CPU의 자원을 `번갈아 가며 할당`받아서 이용한다.

- `타이머 인터럽트(타임아웃 인터럽트,timer interrupt)`  
  : 시간이 끝났음을 알리는 인터럽트, 프로세스의 CPU 사용 시간은 타이머 인터럽트에 의해 제한됩니다.
  정해진 시간만큼 CPU를 이용하고, 타이머 인터럽트가 발생하면 자신의 차례를 양보하고 다음 차례가 올 때까지 기다린다.
- `문맥(context)` : 프로세스의 수행을 재개하기 위해 기억해야 할 정보(프로그램 카운터를 비롯한 각종 레지스터 값과 메모리 정보, 실행을 위해 열었던 파일, 사용한 입출력장치 등)
- 프로세스 할당 순서

  1.  차례가 된 프로세스가 정해진 시간동안 CPU 에 할당된다.
  2.  시간이 다 되면 지금까지의 context를 해당 프로세스의 PCB에 백업한다.
  3.  다음 차례에 시행할 프로세스의 context를 복구한다.

  `문맥 교환(context switching)` : 기존 프로세스의 문맥을 PCB에 백업하고, PCB에서 문맥을 복구하여 새로운 프로세스를 실행하는 과정

  프로세스 간에 너무 잦은 문맥 교환이 발생하면 캐시 미스가 발생할 가능성이 높아져 메모리로부터 실행할 프로세스의 내용을 가져오는 작업이 빈번해지고, 이는 큰 오버헤드로 이어질 수 있기 때문입니다.

### 프로세스의 상태

- `생성 상태(new)`  
  : 프로세스를 생성 중인 상태로, 메모리에 적재되어 PCB를 할당받은 상태

- `준비 상태(ready)`  
  : 생성 상태를 거쳐 실행할 준비가 완료된 프로세스  
  준비 상태인 프로세스가 CPU를 할당받으면 실행 상태가 되며, 준비 상태인 프로세스가 실행 상태로 전환되는 것을 `디스패치(dispatch)`라고 한다.

- `실행 상태(running)`  
  : 실행 상태는 CPU를 할당받아 실행 중인 상태, 일정 시간 동안만 CPU를 사용할 수 있다.  
  타이머 인터럽트 발생 => 준비 상태로 전환 / 입출력장치 사용 => 대기 상태로 전환

- `대기 상태(blocked)`  
  : 프로세스가 입출력 작업을 요청하거나 바로 확보할 수 없는 자원을 요청하는 등 곧장 실행이 불가능한 조건
  에 놓이는 경우 대기 상태로 전환.  
  대기 상태였던 해당 프로세스는 입출력 작업이 완료되는 등 실행 가능한 상태가 되면 다시 준비 상태가 되어 CPU 할당을 기다린다.

  `+ 블로킹 입출력과 논블로킹 입출력`  
   프로세스가 실행 도중 입출력 작업을 수행해야 하는 경우,
  (1) `블로킹 입출력(blocking I/O)` : 입출력 작업이 완료되면 대기 -> 준비 상태로 전환하여 실행을 재개

  (2) `논블로킹 입출력(non-blocking I/O)` : 입출력장치에게 입출력 작업을 맡긴 뒤, 곧바로 이어질 명령어를 실행

- `종료 상태(terminated)`  
  : 종료 상태는 프로세스가 종료된 상태  
  프로세스가 종료되면 운영체제는 PCB와 프로세스가 사용한 메모리를 정리

### 멀티프로세스와 멀티스레드

`멀티프로세스(multi-process)`

- 동시에 여러 프로세스가 실행되는 것 (e.g. 웹 브라우저)
- 각각의 프로세스들은 기본적으로 <u>자원을 공유하지 않고</u> 독립적으로 실행된다.  
  => 각각의 PID(프로세스 ID) 값이 다르고, 프로세스별로 자원이 독립적으로 할당되어 다른 프로세스에 영향 X

`멀티스레드(multi-thread)`

- 프로세스를 동시에 실행하는 여러 스레드
- 각각의 스레드는 스레드를 식별할 수 있는 고유 정보인 스레드 ID와 프로그램 카운터, 레지스터 값, 스택 등으로 구성 => 스레드마다 다음에 실행할 주소를 가질 수 있고, 연산 과정의 임시 저장 값을 가질 수 있다.
- <u>같은 프로세스를 실행하는 여러 스레드들은 프로세스의 자원을 공유</u>한다.  
  => 멀티스레드 환경에서는 한 스레드에 생긴 문제가 프로세스 전체의 문제가 될 수 있다.

`스레드 조인(thread join)`
: join은 스레드를 생성한 주체가 ‘생성/실행된 스레드가 종료될 때까지 대기’해야 함

e.g. ‘main’ 스레드가 ‘a’ 스레드를 생성할 때 join을 호출  
=> ‘main’ 스레드는 생성한 ‘a’ 스레드가 종료될 때까지 실행되지 않고 대기

### 프로세스 간 통신

`프로세스 간 통신(IPC, Inter-Process Communication)`

- 프로세스는 기본적으로 자원을 공유하지 않지만, 프로세스 간에도 자원을 공유하고 데이터를 주고
  받을 수 있는 방법이 있다.

  - `(1)` `공유 메모리shared memory`

    - 프로세스 간에 공유하는 메모리 영역을 토대로 데이터를 주고받는 통신 방식
    - 공유 메모리라는 특별한 메모리 공간을 할당하여 프로세스가 해당 메모리 공간을 공유하여  
      통신을 주고받는 각 프로세스가 마치 자신의 메모리 영역을 읽고 쓰는 것처럼 통신한다.
    - 프로세스가 데이터를 주고받는 과정에 커널의 개입이 거의 없다.
    - 통신 속도가 빠르나 데이터의 일관성 훼손 가능(레이스 컨디션)

  - `(2)` `메시지 전달`

    - 메시지 전달은 프로세스 간에 주고받을 데이터가 커널을 거쳐 송수신되는 통신 방식
    - 메시지를 보내는 수단과 받는 수단이 명확하게 구분되어 있다.
    - 통신 속도가 느리나 레이스 컨디션 고려 덜 해도 된다.
    - 대표적인 수단 : 파이프, 시그널, 소켓, 원격 프로시저 호출(RPC)
      - `파이프(pipe)`란 단방향 프로세스 간의 통신 도구(데이터가 흐를 수 있는 공간)  
         `익명 파이프(unnamed pipe)` : 단방향 통신 수단인 전통적인 파이프, 부모 프로세스와 자식 프로세스 간에만 통신이 가능
        `지명 파이프(named pipe)` : 양방향 통신을 지원하며, 부모 프로세스와 자식 프로세스 뿐만 아니라 임의의 프로세스 간에도 사용 가능

  - `(3)` `시그널(signal)` : 프로세스에게 특정 이벤트(event)가 발생했음을 알리는 비동기적인 신호

    - 프로세스는 시그널이 발생하면 여느 인터럽트 처리 과정과 유사하게 하던 일을 잠시 중단하고, 시그
      널 처리를 위한 `시그널 핸들러(signal handler)`를 실행한 뒤 실행을 재개합니다.  
      이때 프로세스는 직접 특정 시그널을 발생 및 일부 시그널 핸들러를 (재)정의 가능하다.
      => 시그널이 발생했을 때의 동작을 정의하여 프로세스에게 해당 시그널을 보냄으로써 프로세스 간 통신을 수행할 수 있다.
    - 시그널을 이용하는 방법은 앞선 IPC 기법들과 다르게 직접적으로 메시지를 주고받지는 않지만, 비
      동기적으로 원하는 동작을 수행할 수 있는 좋은 수단임

    - 시그널의 기본 동작은 대부분 프로세스를 종료하거나 무시하거나 코어 덤프 생성
    - `코어 덤프(core dump)` : 주로 비정상적으로 종료하는 경우에 생성되는 파일, 프로그램이 특정 시점에 작업하던 메모리 상태가 기록되어 있다.

  - 그 외 : 원격 프로시저 호출(RPC), 네트워크 소켓

## 3. 동기화와 교착 상태

### 간단한 용어 정리

- `공유 자원(shared resource)` : 프로세스 혹은 스레드가 공유하는 자원

- `임계 구역(critical section)` : 공유 자원에 접근하는 코드 중 동시에 실행했을 때 문제가 발생할 수 있는 코드  
   => 동시에 실행되는 프로세스나 스레드가 동시에 임계 구역에 진입하여 실행되면 문제가 발생할 수 있습니다

- `레이스 컨디션(race condition)` : 프로세스 혹은 스레드가 동시에 임계 구역의 코드를 실행하여 문제가 발생하는 상황  
   자원의 일관성이 손상될 수 있기 때문에 2개 이상의 프로세스 혹은 스레드가 임계 영역에 진입하고자 한다면 둘 중 하나는 작업이 끝날 때까지 대기해야 한다.

레이스 컨디션을 방지하면서 임계 구역을 관리하기 위해서는 프로세스와 스레드가 동기화되어야 합
니다.

### 동기화

`프로세스와 스레드의 동기화(synchronization)`란 다음의 2가지 조건을 준수하며 실행하는 것을 의미한다.

- `실행 순서 제어` : 프로세스 및 스레드를 올바른 순서로 실행하기  
  e.g. 쓰고 읽어야하는데 반대로 수행
- `상호 배제` : 동시에 접근해서는 안 되는 자원에 하나의 프로세스 및 스레드만 접근하기  
  e.g. 두 프로세스 모두 동일한 공유자원을 수정

### 동기화 기법

`1. 뮤텍스 락(mutex lock)`

- 동시에 접근해서는 안 되는 자원에 동시 접근이 불가능하도록 상호 배제를 보장하는 동기화 도구
- 하나의 공유 자원을 고려하는 동기화 도구
  `임계 구역에 접근하고자 한다면 반드시 락(lock)을 획득(acquire)해야 하고, 임계 구역에서의 작업이 끝났다면 락을 해제(release)해야 한다.`
- 프로세스 및 스레드가 공유하는 변수(lock)와 2개의 함수(acquire, release)로 구현

  - 변수 `lock` : 프로세스 및 스레드가 공유하는 변수
  - 함수 `acquire()` : 락을 획득하기 위한 함수로, 특정 락에 대해 한 번만 호출이 가능한 함수  
    (다른 곳에서 해제하기 전까지는 사용 X)
  - 함수 `release()` : 획득한 락을 해제하기 위한 함수

  > 1. lock.acquire()을 호출하여 임계 구역에 진입 (다른 프로세스 및 스레드는 락이 해제될 때까지 기다려야 한다.)
  > 2. 임계 구역의 작업이 끝나면 락을 해제하기 위해 lock.release()를 호출
  > 3. 임계 구역 앞에서 대기하는 프로세스 혹은 스레드가 있다면 해제된 락을 획득하고(lock.acquire() 호출에 성공하고) 임계 구역에 진입

`2. 세마포(semaphore)`

- 여러 개의 공유 자원이 있는 상황에서도 동기화 가능
- 다음과 같은 하나의 변수와 2개의 함수로 구성

  - 변수 `S`: 사용 가능한 공유 자원의 개수를 나타내는 변수 (+ 대기중인 프로세스 및 스레드가 몇개인지도 나타냄)
    공유 자원의 개수가 S개 => 임계 구역에 진입하여 동시에 실행 가능한 프로세스 혹은 스레드도 S개
  - 함수 `wait()`: 임계 구역 진입 전 호출하는 함수
  - 함수 `signal()`: 임계 구역 진입 후 호출하는 함수

  > 1. `wait()`을 호출하면 s = s-1
  >    s >= 0 이면 임계 구역 진입, s < 0 이면 대기 큐에 삽입
  > 2. `signal()`을 호출하면 s = s + 1
  >    s >= 0 이면 대기 상태로 접어든 프로세스 중 하나를 준비 상태로 전환

  ***

  `e.g.`  
   (1) 프로세스 P1 wait() 호출, S를 1 감소시키면 S = 1이므로 임계 구역 진입  
   (2) 프로세스 P2 wait() 호출, S를 1 감소시키면 S = 0이므로 임계 구역 진입  
   (3) 프로세스 P3 wait() 호출, S를 1 감소시키면 S = -1이므로 대기 상태로 전환  
   (4) 프로세스 P1 임계 구역 작업 종료. signal() 호출, S를 1 증가시키면 S = 0이므로 대기 상태였던 P3을 준비 상태로 전환  
   (5) 깨어난 프로세스 P3 임계 구역 진입  
   (6) 프로세스 P2 임계 구역 작업 종료. signal() 호출, S를 1 증가시키면 S = 1  
   (7) 프로세스 P3 임계 구역 작업 종료. signal() 호출, S를 1 증가시키면 S = 2

  ***

  - 이진 세마포와 카운팅 세마포  
    공유 자원이 1개이면 `이진 세마포(binary semaphore)` : S가 0과 1의 값을 가지는 세마포
    공유 자원이 2개 이상이면 `카운팅 세마포(counting semaphore)`

  - 여기서의 자원이란 무엇일까?

    | 상황         | 자원의 의미       | 세마포 S 값 | S의 역할                       |
    | ------------ | ----------------- | ----------- | ------------------------------ |
    | 프린터 1대   | 물리 장비 1개     | 1           | 동시에 한 프로세스만 접근 가능 |
    | DB 커넥션 풀 | 커넥션 10개       | 10          | 최대 10개 동시 연결 허용       |
    | 화장실       | 칸 3개            | 3           | 3명까지 동시 입장 가능         |
    | 작업 스레드  | 작업 슬롯 20개    | 20          | 최대 20개 동시 작업 허용       |
    | 다운로드     | 동시 접속 허용 수 | 5           | 최대 5명 동시 다운로드         |

`3. 모니터`

- `조건 변수(condition variable)`란 실행 순서 제어를 위한 동기화 도구, 특정 조건 하에 프로세스를 실행/일시 중단함으로써 프로세스나 스레드의 실행 순서를 제어할 수 있다.
- 조건 변수에 대해 wait()와 signal() 함수를 호출할 수 있다.
  - 함수 `wait()` : 호출한 프로세스 및 스레드의 상태를 대기 상태로 전환하는 함수
  - 함수 `signal()` : wait()로 일시 중지된 프로세스 및 스레드의 실행 재개하는 함수
    > - 아직 특정 프로세스가 실행될 조건이 되지 않았을 때는 wait()를 통해 실행을 중단한다.
    > - 특정 프로세스가 실행될 조건이 충족되었을 때는 signal()을 통해 실행을 재개한다

---

- `모니터(monitor)` : 공유 자원과 그 공유 자원을 다루는 함수(인터페이스)로 구성된 동기화 도구  
  상호 배제를 위한 동기화뿐만 아니라 <u>실행 순서 제어를 위한 동기화</u>까지 가능

- 모니터의 작동원리  
   프로세스 및 스레드는 공유 자원에 접근하기 위해 반드시 정해진 공유 자원 연산(인터페이스)을 통해 모니터 내로 진입해야 하고, 모니터 안에 진입하여 실행되는 프로세스 및 스레드는 항상 하나여야 합니다. 이미 모니터 내로 진입하여 실행 중인 프로세스 및 스레드가 있다면 큐에서 대기해야 한다.

  e.g. 프로세스 A, B 중 반드시 A가 먼저 실행되고, 다음으로 B가 실행되어야 한다
  => 프로세스 B는 모니터 내에서 실행되기에 앞서 프로세스 A의 실행이 끝났는지를 검사  
   if (프로세스 A 완료) => 모니터 진입
  else => wait() , B는 큐에서 대기
  이후에 signal() 호출하면 대기하던 B가 실행

`스레드 안전`

- `스레드 안전(thread safety)` : 멀티스레드 환경에서 어떤 변수나 함수, 객체에 동시 접근이 이루어져도 실행에 문제가 없는 상태
  레이스 컨디션이 발생했다면 이는 스레드 안전하지 않은 상황인 것이죠. 반대로 어떤 함수가 스레드 안전하다면, 이는
  여러 스레드에 의해 호출되어도 레이스 컨디션이 발생하지 않는 것을 의미합니다

### 교착 상태(deadlock)

- 일어나지 않을 사건을 기다리며 프로세스의 진행이 멈춰 버리는 현상
- 교착 상태의 발생조건

  - `상호 배제`  
    교착 상태가 발생하는 근본적인 원인은 한 번에 하나의 프로세스만 해당 자원을 이용 가능했기 때문 즉, 한 프로세스가 사용하는 자원을 다른 프로세스가 사용할 수 없는 상호 배제의 상황에서 교착 상태가 발생할 수 있다.
  - `점유와 대기(hold and wait)`
    한 프로세스가 어떤 자원을 할당받은 상태(점유)에서 다른 자원 할당받기를 기다린다면(대기) 교착 상태가 발생할 수 있다
  - `비선점`  
    자원이 비선점되었다 == 해당 자원을 이용하는 프로세스의 작업이 끝나야만 비로소 자원을 이용할 수 있다.
    => 어떤 프로세스도 다른 프로세스의 자원을 강제로 빼앗지 못함
  - `원형 대기`  
    각각의 프로세스가 서로 점유한 자원을 할당받기 위해 원의 형태로 대기할 경우 교착 상태가 발생할 수 있다

- 교착 상태 해결 방법
  - 교착 상태 `예방`  
    : 교착 상태 발생 필요 조건 중 하나를 충족하지 못하게 하는 방법  
    프로세스에 자원을 할당할 때 상호 배제, 점유와 대기, 비선점, 원형 대기 중 하나라도 만족하지 않으면 교착 상태가 발생하지 않기 때문이다.  
    점유와 대기 => 한 프로세스에 필요한 자원들을 몰아 주고, 그 다음에 다른 프로세스에 필요한 자원을 몰아주기  
    원형 대기 => 할당 가능한 모든 자원에 번호를 매기고 오름차순으로 할당
  - 교착 상태 `회피`  
    : 교착 상태가 발생하지 않을 정도로만 조심하면서 자원을 할당하는 방법  
    <u>교착 상태 = 한정된 자원의 무분별한 할당으로 인해 발생하는 문제로 간주</u>  
    프로세스에 할당할 수 있는 자원이 충분한 상황에서 프로세스들이 한두 개의 적은 자원만을 요구하기  
    e.g. 은행원 알고리즘(banker’s algorithm)
  - 교착 상태 `검출 후 회복`  
    : 상태의 발생을 인정하고 처리하는 사후 조치  
    운영체제는 프로세스가 자원을 요구할 때마다 그때 그때 자원을 할당하고 주기적으로 교착 상태의 발생 여부를 검사, 교착 상태가 검출 시 자원 선점을 통해 회복시키거나, 프로세스를 강제 종료함으로써 회복한다.  
    (자원 선점을 통한 회복 : 교착 상태가 해결될 때까지 다른 프로세스로부터 강제로 자원을 빼앗아 한 프로세스에 몰아서 할당)

## 4. CPU 스케줄링

`CPU 스케줄링(CPU scheduling)`  
: 운영체제가 프로세스와 스레드에 CPU의 사용을 배분하는 방법  
`CPU 스케줄러(CPU scheduler)`가 CPU 스케줄링 알고리즘을 결정하고 수행한다.

### 우선순위

- 모든 프로세스는 CPU의 자원을 필요로 하기 때문에 운영체제는 CPU의 자원을 단순히 순차적으로 할당하는 것이 아닌, 프로세스별로 우선순위(priority)를 판단하여 PCB에 명시하고, 이에 맞추어 CPU의 자원을 적절하게 할당한다.

- `CPU 활용률(CPU utilization)` : 전체 CPU의 가동 시간 중 작업을 처리하는 시간의 비율  
   운영체제는 가급적 CPU 활용률을 높게 유지할 수 있도록 우선순위를 할당한다.

  > `+` CPU 활용률에서 작업 처리 외 시간 종류
  >
  > - 아이들(idle) 시간

      CPU가 할 일이 없어서 쉬고 있는 상태, 프로세스가 없거나 모두 대기 상태일 때 발생, CPU가 아무 작업도 하지 않고 대기하는 시간

  > - 대기(waiting) 시간

      I/O 작업(디스크, 네트워크 등) 완료를 기다리는 상태, CPU가 아닌 다른 자원(예: 디스크 입출력)을 기다리는 동안의 시간

  > - 시스템 오버헤드(overhead) 시간

      운영체제의 커널 작업, 인터럽트 처리, 문맥 교환 등 CPU가 직접적인 작업 처리 외에 소비하는 시간

대부분의 프로세스들은 CPU와 입출력장치를 모두 사용해 실행과 대기 상태를 오가며 실행된다.

`CPU 버스트(CPU burst)` : 프로세스가 CPU를 이용하는 작업
=> `CPU 집중 프로세스(CPU bound process)` : CPU 작업이 많은 프로세스, 실행 상태에 더 많이 머무른다. <u>(CPU 버스의 빈도가 많은 프로세스)</u>

`입출력 버스트(I/O burst)` : 프로세스가 출력장치를 기다리는 작업
=> `입출력 집중 프로세스(I/O bound process)` : 입출력 작업이 많은 프로세스, 대기 상태에 더 많이 머무른다. <u>입출력 작업이 많아 입출력 버스트의 빈도가 높거나, I/O 작업 사이클이 짧고 자주 발생하는 프로세스</u>

---

<u>모든 프로세스가 동일한 시간의 빈도로 CPU를 사용하는 것은 합리적이지 않다!!</u>  
입출력장치가 입출력 작업을 완료하기 전까지 입출력 집중 프로세스는 어차피 대기 상태가 될 것이므로 얼른 입출력 집중 프로세스를 먼저 처리해 버리면 그 이후에 다른 프로세스를 실행시켜 CPU 활용률을 높일 수 있다. 그래서 <u>입출력 집중 프로세스는 일반적으로 CPU 집중 프로세스보다 우선순위가 높다.</u>

- 운영체제는 높은 CPU 활용률을 유지하기 위해 기본적으로 입출력 작업이 많은 프로세스의 우선순위를 높게 유지합니다.

### 스케줄링 큐

- 운영체제가 프로세스의 상태에 따라 분류하고, 다음 실행 순서를 결정하기 위해 사용하는 프로세스 대기열
- CPU를 이용하고 싶은 프로세스의 PCB와 메모리로 적재되고 싶은 프로세스의 PCB, 특정 입출력장치를 이용하고 싶은 프로세스의 PCB를 큐에 삽입

  - `준비 큐(ready queue)` : CPU를 이용하고 싶은 프로세스의 PCB가 서는 줄
  - `대기 큐(waiting queue)` : 대기 상태에 접어든 프로세스의 PCB가 서는 줄, 입출력장치마다 대기 큐가 존재

    준비 상태인 프로세스는 준비 큐에 삽입되어있고, 대기 상태인 프로세스는 대기 큐에 삽입  
    운영체제는 큐에 삽입된 순서대로 실행하되, 우선순위가 높은 프로세스부터 먼저 실행한다.  
    같은 입출력장치를 요구한 프로세스들은 같은 대기 큐에서 기다린다.  
    완료 인터럽트 발생시 운영체제는 대기 큐에서 작업이 완료된 PCB를 찾고, 이 PCB를 준비 상태로 변경한 뒤 큐에서 제거하고 준비 큐로 이동한다.

### 선점형 스케줄링과 비선점형 스케줄링

| 항목                     | `선점형 스케줄링(preemptive scheduling)`                                  | `비선점형 스케줄링(non-preemptive scheduling)`                         |
| ------------------------ | ------------------------------------------------------------------------- | ---------------------------------------------------------------------- |
| **정의**                 | 실행 중인 프로세스를 강제로 중단하고 다른 프로세스로 CPU를 할당할 수 있음 | 한 번 CPU를 할당받은 프로세스는 스스로 CPU를 반납할 때까지 계속 실행됨 |
| **CPU 제어권 회수 시점** | 타이머 인터럽트, 우선순위 높은 프로세스 도착 등                           | 프로세스가 종료되거나 대기 상태로 전환될 때만                          |
| **응답 시간**            | 일반적으로 더 짧음 (대기 시간이 고르게 분산됨)                            | 응답 시간이 길어질 수 있음                                             |
| **공정성(Fairness)**     | 비교적 공정하게 CPU 분배 가능                                             | 긴 프로세스가 CPU를 독점할 수 있음 (기아 현상 발생 가능)               |
| **문맥 교환(오버헤드)**  | 빈번한 문맥 교환 발생 → 오버헤드 큼                                       | 문맥 교환 횟수 적음 → 오버헤드 작음                                    |
| **사용 예시**            | 실시간 시스템, 멀티태스킹 운영체제(Windows, Linux 등)                     | 단순한 작업 순차 처리 시스템, 배치 처리 시스템 등                      |
| **대표 알고리즘**        | 라운드 로빈(Round Robin), SRTF, 우선순위 기반(선점형) 등                  | FCFS, SJF, 우선순위 기반(비선점형) 등                                  |

### CPU 스케줄링 알고리즘

`비선점형 스케줄링(non-preemptive scheduling)`

- `FCFS(선입 선처리, First Come First Served)`

  - <u>준비 큐에 삽입된 순서대로</u> 먼저 CPU를 요청한 프로세스부터 CPU를 할당하는 스케줄링 방식
  - 먼저 삽입된 프로세스의 오랜 실행 시간으로 인해 나중에 삽입된 프로세스의 실행이 지연되는 문제를 `호위 효과(convoy effect)` 발생 가능

- `SJF(최단 작업 우선, Shortest Job First)`

  - 준비 큐에 삽입된 프로세스 중 <u>CPU를 이용하는 시간의 길이가 가장 짧은</u> 프로세스부터 먼저 실행하는 스케줄링 방식
  - 비선점형 스케줄링 알고리즘으로 분류되지만, '최소 잔여 시간 우선 스케줄링'처럼 선점형으로 구현될 수도 있다.

- `라운드 로빈(round robin)`

  - `FCFS` + `타임 슬라이스(time slice, 프로세스가 CPU를 사용하도록 정해진 시간)`
  - 큐에 삽입된 프로세스들이 삽입된 순서대로 CPU를 이용하되, 정해진 타임 슬라이스만큼만 CPU를 이용하는 선점형 스케줄링, 프로세스가 정해진 시간을 모두 사용하고도 완료되지 않으면 문맥 교환이 발생해 다시 큐의 맨 뒤에 삽입된다.

- `SRT(최소 잔여 시간 우선, Shortest Remaining Time)`

  - `SJF` + `Round robin`
  - 프로세스로 하여금 정해진 타임 슬라이스만큼 CPU를 이용하되, 남아 있는 작업시간이 가장 적은 프로세스를 다음으로 CPU를 이용할 프로세스로 선택한다.

- `우선순위(priority)`

  - 프로세스에 우선순위를 부여하고, 가장 높은 우선순위를 가진 프로세스부터 실행하는 스케줄링 방식
  - 우선순위가 높은 프로세스로 인해 우선순위가 낮은 프로세스의 실행이 연기되는 `아사 현상(starvation)`을 방지하기 위해 `에이징(aging, 오랫동안 대기한 프로세스의 우선순위를 점차 높이는 방식)` 기법 사용

- `다단계 큐(multilevel queue)`

  - 우선순위 스케줄링의 발전된 형태로, 우선순위별로 여러 개의 준비 큐를 사용하는 스케줄링 방식
    우선순위가 가장 높은 큐부터 순차적으로 프로세스 처리한다.
  - 우선순위가 낮은 큐의 프로세스에 아사 현상 발생할 수 있다.

- `다단계 피드백 큐(multilevel feedback queue)`
  - `다단계 큐` + 프로세스들이 큐 사이를 이동 가능
  - 우선순위가 가장 높은 우선순위 큐에 삽입된 프로세스는 타임 슬라이스 동안 실행되며, 해당 큐에서 프로세스의 실행이 끝나지 않으면 <u>다음 우선순위 큐에 삽입</u>되어 실행
  - 에이징 기법 적용할 수도 있음

### 리눅스 CPU 스케줄링

실제 운영체제에서는 프로세스의 가중치에 따라 타임 슬라이스를 달리 할당받을 수도 있다.
실제 리눅스 운영체제의 CPU 스케줄링을 살펴보자.

`리눅스 운영체제의 스케줄링 정책(scheduling policy)`

- `스케줄링 정책(scheduling policy)` : 새로운 프로세스를 언제 어떻게 선택하여 실행할지를 결정하기 위한 규칙의 집합

| **스케줄링 정책** | **적용 상황 (설명)**                                                                            |
| ----------------- | ----------------------------------------------------------------------------------------------- |
| `SCHED_FIFO`      | **실시간** 스케줄링 정책. 우선순위 기반 **비선점형**. 우선순위가 높은 프로세스가 선점.          |
| `SCHED_RR`        | **실시간** 정책. `SCHED_FIFO`와 유사하지만 **라운드 로빈 방식**으로 **선점형**.                 |
| `SCHED_OTHER`     | **기본 정책 (CFS - Completely Fair Scheduler)**. 일반적인 **비실시간** 프로세스에 적용.         |
| `SCHED_BATCH`     | **배치 작업용 정책**. 사용자와의 인터랙션이 적고, CPU 사용량이 높은 프로세스에 적합.            |
| `SCHED_IDLE`      | **가장 낮은 우선순위**. 시스템이 유휴 상태일 때만 실행. 백그라운드에서 실행되는 작업 등에 사용. |

- `SCHED_FIFO(First-In-First-Out)`와 `SCHED_RR(Round Robin)`  
  RTReal-Time 스케줄러에 의해 이뤄지는 스케줄링
  실시간성이 강조된 프로세스(실시간 프로세스)에 적용되는 스케줄링 정책

- `SCHED_NORMAL`
  일반적인 프로세스에 적용되는 스케줄링 정책

- `CFS(Completely Fair Scheduler)`  
   프로세스에 대해 '완전히 공평한 CPU 시간 배분'을 지향하는 CPU 스케줄러  
   리눅스에서는 프로세스마다 `가상 실행 시간(vruntime, virtual runtime)`이라는 정보를 유지하는데,  
   CFS는 이 vruntime이 가장 작은 프로세스부터 스케줄링한다.

  - vruntime은 프로세스가 '실제로 실행된 시간(runtime)'이 아닌, 프로세스의 '가중치(weight, 프로세스의 우선순위와 연관된 값으로, 프로세스의 우선순위가 높아질수록 가중치도 높아진다)'를 고려한 가상의 실행 시간  
    => 프로세스의 가중치가 높아질수록 vruntime이 천천히 증가, 따라서 프로세스의 가중치가 높을수록 먼저 스케줄링될 확률이 높다.

  CFS로 스케줄링되는 프로세스들의 타임 슬라이스는 프로세스의 우선순위가 높아질수록 가중치도 높아진다. 프로세스의 가중치가 높아지면 타임 슬라이스도 크게 할당받을 수 있다.

  > 커널(CFS 스케줄러)은 수많은 프로세스 중 vruntime이 가장 작은 프로세스를 빠르게 선별하기 위해 RB 트리를 사용한다.

## 5. 가상 메모리

- `물리 주소(physical address)`  
  : 메모리의 하드웨어 상 실제 주소
- `논리 주소(logical address)`  
  : 프로세스마다 부여되는 0번지부터 시작하는 주소 체계  
  <u>메모리 상에 적재된 모든 프로세스는 0번지부터 시작하는 각자의 논리 주소를 가지고 있다.</u> => 중복되는 논리 주소의 번지 수 존재 가능

`메모리 관리 장치(MMU,Memory Management Unit)` : MMU는 CPU와 메모리 사이에 위치하며, CPU가 이해하는 논리 주소를 메모리가 이해하는 물리 주소로 변환하는 하드웨어

### 스와핑과 연속 메모리 할당

`스와핑(swapping)`

- 메모리에 적재된 프로세스들 중에는 현재 실행되고 있지 않은 프로세스(입출력 작업을 요구하며 대기 상태가 되었거나 오랫동안 사용되지 않은 프로세스)들을 임시로 `스왑 영역(swap space)`라는 보조기억장치의 일부인 영역으로 쫓아내고, 프로세스를 쫓아낸 자리에 생긴 메모리 상의 빈 공간에 다른 프로세스를 적재하여 실행하는 메모리 관리 방식

`+` `스왑 영역(Swap space)`: 디스크(SSD/HDD)에 설정된 비휘발성 저장 공간으로, 메모리가 부족할 때 일시적으로 데이터를 대피시켜 놓는 용도로 사용

- `스왑 아웃(swap-out)` : 현재 실행되지 않는 프로세스가 메모리에서 스왑 영역으로 옮겨지는 것
- `스왑 인(swap-in)` : 스왑 영역에 있는 프로세스가 다시 메모리로 옮겨오는 것 (이전과 동일한 물리 주소로 옮겨오는 것 X)

**Q. 만약 메모리 내 빈 공간이 여러 개라면 어디에 프로세스를 배치해야 할까?**

`연속 메모리 할당` : 프로세스에 연속적인 메모리 공간을 할당하는 방식 (프로세스를 한 덩어리로 연속적으로 할당)  
=> 프로세스의 실행과 종료를 반복하며 생기는 빈 공간에 그보다 큰 프로세스를 적재하기 여러움(`외부 단편화(external fragmentation)`)

`가상 메모리(virtual memory)`  
: 실행하고자 하는 프로그램의 일부만 메모리에 적재해, 실제 메모리보다 더 큰 프로세스를 실행할 수 있도록 만드는 메모리 관리 기법  
보조기억장치의 일부를 메모리처럼 사용하거나 프로세스의 일부만 메모리에 적재함으로써 메모리를 실제 크기보다 더 크게 보이게 하는 기술

=> `가상 주소 공간(virtual address space)` : 가상 메모리 기법으로 생성된 논리 주소 공간

- 가상 메모리 관리 기법 : 페이징 과 세그멘테이션

  - `페이징(paging)`

    - 프로세스의 논리 주소 공간을 `페이지(page)`라는 일정한 단위로 나누고, 물리 주소 공간을 페이지와 동일한 크기의 `프레임(frame)`이라는 일정한 단위로 나눈 뒤 페이지를 프레임에 할당하는 가상 메모리 관리 기법
    - 프로세스를 구성하는 페이지는 물리 메모리 내에 불연속적으로 배치될 수 있다.
    - 일정한 크기(페이지)로 잘린 프로세스들을 메모리에 불연속적으로 할당하여 프로세스 바깥에 빈 공간을 만들지 않아 외부 단편화가 발생하지 않는다.

  - 모든 프로세스가 페이지 크기에 딱 맞게 잘리는 것이 아니므로, 마지막 페이지에 페이지의 크기보다 작은 크기가 할당될 때 `내부 단편화(Internal Fragmentation)` 발생한다.

  - `세그멘테이션(segmentation)`
    - 프로세스를 일정한 크기의 페이지 단위가 아닌 가변적인 크기의 세그먼트(segment) 단위로 분할하는 방식
    - 세그멘테이션 기법을 사용하면 세그먼트의 크기가 일정하지 않기 때문에 외부 단편화가 발생할 수 있다.

페이징을 사용하는 시스템에서는 페이지 단위로 스왑 아웃/스왑 인(`페이지 아웃(page out)`, `페이지 인(page in)`)된다.  
페이지 아웃, 페이지 인도 스왑 영역으로 이동하는 것

- 프로세스의 일부는 메모리에 적재되고, 일부는 보조기억장치에 적재 == <u>프로세스를 실행하기 위해 전체 프로세스가 메모리에 적재될 필요는 없다</u>
  => CPU 입장에서 바라본 논리 메모리의 크기가 실제 메모리보다 클 수 있다는 것
  => 페이징을 통해 물리 메모리보다 큰 크기의 프로세스 실행도 가능해진다. (4GB 메모리로 8GB 프로그램 실행 가능)

### 페이지테이블

`페이지 테이블(page table)`

- 프로세스의 페이지 번호와 실제로 적재된 프레임 번호가 대응되어 있는 테이블
- 페이지는 물리 메모리 내에 불연속적으로 배치될 수 있으므로, CPU는 프로세스를 실행할 때는 각 프로세스가 가지는 `페이지 테이블`을 참조하여 메모리에 접근한다.
- `페이지 테이블 엔트리(PTE, Page Table Entry)`: 페이지 테이블을 구성하는 행

  - `유효 비트(valid bit)`  
    : 해당 페이지가 메모리, 아니면 보조기억장치에 적재되어 있는지 알려 주는 비트  
    (1 : 메모리에 적재되어 있음, 0 : 메모리에 X )  
    CPU가 메모리에 적재되지 않은 페이지(유효 비트가 0인 페이지)에 접근하려고 하면 `페이지 폴트(page fault)`라는 예외(Exception)가 발생한다.

    > 페이지 폴트 발생시  
    > (1) 기존 작업 내역을 백업  
    > (2) 페이지 폴트 처리 루틴을 실행한다. 원하는 페이지를 메모리로 가져와 유효 비트를 1로 변경한다.  
    > (3) 페이지 폴트 처리 루틴 실행 후, 메모리에 적재된 페이지를 실행한다.

  - `보호 비트(protection bit)` : 페이지 보호 기능을 위해 존재하는 비트
    `r w x`(읽기 read, 쓰기 write, 실행 execute) 조합으로 페이지에 접근할 권한을 제한함으로써 페이지를 보호한다.
    e.g. 100으로 설정된 페이지 => r=1, w=0, x=0 (읽기만 가능)

  - `참조 비트(reference bit)` : CPU가 해당 페이지에 접근한 적이 있는지의 여부를 나타내는 비트입니다. 페이지에 적재한 이후에 CPU가 읽거나 쓴 페이지는 참조 비트가 1로 설정되고, 적재한 이후에 한 번도 읽거나 쓴 적이 없는 페이지는 0으로 유지됩니다.

  - `수정 비트(modified bit, dirty bit)` : 해당 페이지에 데이터를 쓴 적이 있는지의 여부를 알려 주는 비트  
    1 = 변경된 적이 있는 페이지 => 메모리에서 삭제시에 보조기억장치에 쓰기 작업 필요  
    0 = 변경된 적이 없는 페이지(한 번도 접근한 적 없거나 읽기만 했던 페이지)

`페이지 테이블 베이스 레지스터(PTBR, Page Table Base Regiser)` : CPU가 실행하고자 하는 프로세스에 맞는 페이지 테이블이 적재된 위치의 정보를 가지는 레지스터  
PTBR은 프로세스마다 가지는 정보이므로 각 PCB에 기록되며, 다른 프로세스로의 문맥 교환이 발생할 때 변경된다.

### 페이지 테이블 관리

모든 프로세스의 페이지 테이블을 메모리에 두는 것은 다음과 같은 단점이 존재한다.

- 메모리 접근 횟수

  모든 프로세스의 페이지 테이블이 메모리에 적재되어 있을 경우, CPU는 페이지 테이블에 접근하기 위해 한 번, 실제 프레임에 접근하기 위해 한 번, 이렇게 총 두 번 메모리에 접근해야 함 -> 메모리에 접근하는 시간이 두 배로 늘어날 수 있다.  
  => `TLB(Translation Look-aside Buffer)`라는 페이지 테이블의 캐시 메모리가 사용된다. <u>참조 지역성의 원리에 근거해 자주 사용할 법한 페이지 위주로 페이지 테이블의 일부 내용을 저장</u>한다.

  `TLB 히트(TLB hit)` : CPU가 접근하려는 논리 주소의 페이지 번호가 TLB에 있을 경우 == 한 번만 메모리에 접근  
  `TLB 미스(TLB miss)` : CPU가 접근하려는 논리 주소의 페이지 번호가 TLB에 없는 경우 == 페이지가 적재된 프레임을 알기 위해 메모리 내의 페이지 테이블에 접근
  메모리 접근 횟수를 낮추려면 TLB 히트율을 높여야 한다.(캐시 히트/미스와 유사)

- 메모리 용량  
  프로세스의 크기가 커지면 자연히 페이지 테이블의 크기도 커지기 때문에 프로세스를 이루는 모든 페이지 테이블 엔트리들을 메모리에 두는 것은 큰 메모리 낭비이다.  
  => `계층적 페이징(hierarchical paging)` : 페이지 테이블을 페이징하는 방식으로, 여러 단계의 페이지를 둔다는 점에서 `다단계 페이지 테이블(multilevel page table)` 기법이라고도 부릅니다.

  프로세스의 페이지 테이블을 여러 개의 페이지로 자르고, CPU와 가까이 위치한 바깥 쪽에 페이지 테이블(Outer 페이지 테이블)을 하나 더 두어 잘린 페이지 테이블의 페이지들을 가리키게 합니다. 이렇게 페이지 테이블을 계층적으로 구성하면 모든 페이지 테이블을 항상 메모리에 유지할 필요가 없어집니다. CPU와 가장 가까이 위치한 페이지 테이블(Outer 페이지 테이블)만 메모리에 유지하면 잘린 페이지 테이블의 일부가 보조기억장치에 있더라도 Outer 페이지 테이블을 통해 언제든 접근할 수 있기 때문입니다.

### 페이징 주소 체계

페이징 시스템의 논리 주소는 기본적으로 <페이지 번호, 변위>와 같은 형태로 이루어져 있습니다.
`페이지 번호(page number)`와 `변위(offset)`  
: `페이지 번호`를 통해 페이지의 위치를 알아내고, `변위`로 접근하려는 주소가 페이지(프레임) 시작 번지로부터 얼만큼 떨어져 있는지를 알 수 있다.  
논리 주소 <페이지 번호, 변위> -> 변환(페이지 테이블) -> 물리 주소 <프레임 번호, 변위>

### 페이지 교체 알고리즘

`요구 페이징(demand paging)`

- 메모리에 프로세스를 적재할 때 처음부터 모든 페이지를 적재하지 않고, 메모리에 필요한(요구되는) 페이지만을 적재하는 기법

> 1. CPU가 특정 페이지에 접근하는 명령어를 실행한다.
> 2. 해당 페이지가 현재 메모리에 있을 경우(유효 비트가 1일 경우) CPU는 페이지가 적재된 프레임에 접근한다.
> 3. 해당 페이지가 현재 메모리에 없을 경우(유효 비트가 0일 경우) 페이지 폴트가 발생한다.
> 4. 페이지 폴트가 발생하면 페이지 폴트 처리 루틴을 통해 해당 페이지를 메모리로 적재하고, 유효 비트를 1로 설정한다.
> 5. 다시 (1)의 과정을 수행

`+` `순수 요구 페이징(pure demand paging)`  
아무런 페이지도 메모리에 적재하지 않은 상태에서 프로세스가 시작되는 경우  
프로세스의 첫 명령어를 실행하는 순간부터 페이지 폴트가 발생하게 되고, 실행에 필요한 페이지가 어느 정도 적재된 이후부터는 페이지 폴트의 발생 빈도가 떨어집니다.

`페이지 교체 알고리즘(page replacement algorithm)`  
메모리에 페이지를 적재하면서 스왑 아웃이 필요한 경우 내보낼 페이지를 선택하는 방법
적재된 일부 페이지를 스왑 아웃할 때 메모리에 적재된 페이지 중 보조기억장치로 내보낼 페이지를 선택하는 방법  
빈번한 페이지 폴트의 발생은 보조기억장치로부터 필요한 페이지를 가져와야 하는 시간만큼 성능 저하를 가져온다.

`+` `스래싱(thrashing)` : 프로세스가 실제로 실행되는 시간보다 페이징에 더 많은 시간을 소요하여 성능이 저하되는 상태

- `FIFO(First-In First-Out)`  
  : 메모리에 가장 먼저 적재된 페이지부터 스왑 아웃

- `최적 페이지 교체 알고리즘(Optimal Page Replacement Algorithm)`  
  : 앞으로의 사용 빈도가 가장 낮은 페이지를 교체하는 알고리즘  
  메모리에 적재된 페이지들 중 앞으로 가장 적게 사용할 페이지를 스왑 아웃해 가장 낮은 페이지 폴트율 But, ‘앞으로 가장 적게 사용할 페이지’를 미리 예측하기가 어렵기 때문에 실제 구현이 어려운 알고리즘

- `LRU(Least Recently Used)`
  : 가장 적게 사용한 페이지를 교체하는 알고리즘

### 페이지 폴트의 종류

보조기억장치와의 입출력 작업이 필요한 페이지 폴트(접근하려는 페이지가 물리 페이지에 없음)인가요?

- YES => `메이저 페이지 폴트(major page fault)`
- NO => `마이너 페이지 폴트(minor page fault)`

| 항목              | CPU 스케줄링 알고리즘                                   | 페이지 교체 알고리즘                                         |
| ----------------- | ------------------------------------------------------- | ------------------------------------------------------------ |
| **목적**          | 어떤 **프로세스를 언제 실행할지** 결정 (시간 자원 관리) | 어떤 **페이지를 메모리에서 제거할지** 결정 (공간 자원 관리)  |
| **자원**          | CPU (처리 시간 중심)                                    | 메모리 (공간 용량 중심)                                      |
| **적용 시점**     | CPU가 유휴 상태일 때 (준비 큐에서 하나 선택)            | 페이지 폴트가 발생해 새로운 페이지를 메모리에 적재해야 할 때 |
| **대표 알고리즘** | FCFS, SJF, Round Robin, Priority, MLQ 등                | FIFO, LRU, LFU, Optimal 등                                   |
| **관련 개념**     | 프로세스 상태(준비/실행/대기), 컨텍스트 스위칭          | 가상 메모리, 페이지 폴트, 프레임                             |

## 6. 파일 시스템

`파일 시스템(file system)`  
: 보조기억장치의 정보를 파일 및 디렉터리(폴더)의 형태로 저장하고 관리할 수 있도록 하는 운영체제 내부 프로그램  
한 운영체제 내에서도 여러 파일 시스템을 사용할 수 있다.  
(우리가 USB에 담긴 데이터를 디렉터리 형태로 볼 수 있는 것은 다 파일 시스템 덕분이다!)

### 파일과 디렉터리

파일 시스템을 이해하려면 먼저 파일과 디렉터리가 무엇으로 이루어져 있는지, 파일과 디렉터리가 보조기억장치에 어떻게 저장될 수 있는지 이해해야 합니다

`파일(file)`

- 구성 요소 : 파일의 이름, 파일을 실행하기 위한 정보, 파일과 관련한 부가 정보(`속성(attribute)` 또는 `메타데이터(metadata)` / 파일 형식, 위치 크기 등)

`파일 디스크립터(또는 파일 핸들, file descriptor)`

- 0 이상의 정수, 저수준에서 파일을 식별하는 정보  
  운영체제는 프로세스가 새로 파일을 열거나 생성할 때 해당 파일에 대한 파일 디스크립터를 프로세스에 할당합니다.

e.g.
open() - 연 파일의 파일 디스크립터를 반환  
write()/close() - 파일 디스크립터를 인자로 받음

- 파일뿐만 아니라 입출력장치, 파이프, 소켓도 파일 디스크립터로 식별
- 파일 디스크립터 ‘0, 1, 2’는 표준 입력, 표준 출력, 표준 에러를 나타내기 위해 할당

### 디렉터리

`디렉터리(directory)`

- 운영체제가 여러 파일을 효율적으로 관리하기 위해 사용하는 논리적인 구조, 파일들을 그룹으로 묶고 계층적으로 조직하는 역할을 한다.
- `트리 구조 디렉터리(tree-structured directory)` : 오늘날의 대부분의 운영체제에서는 디렉터리는 트리 구조로 구성하여 계층적 파일 시스템을 제공한다.  
  (윈도우 운영체제에서는 `폴더(folder)`)

- `경로(path)` : 디렉터리 정보를 활용해 파일 위치를 특정하는 정보

  `루트 디렉터리root directory` : 최상위 디렉터리, 슬래시(/)로 표현
  윈도우 운영체제에서는 최상위 디렉터리를 흔히 ‘C:\’로 표현하고, 백슬래시(키보드의 \)를 디렉터리 구분자로 사용

운영체제에서는 디렉터리 또한 페이지처럼 테이블의 형태로 표현 (‘디렉터리에 속한 요소의 관련 정보가 포함된 파일’)

`디렉터리 엔트리(directory entry)` : 디렉터리에 속한 요소

- 디렉터리 엔트리에는 ‘파일의 이름’과 ‘파일이 저장된 위치를 유추할 수 있는 정보’가 반드시 포함 디렉터리
- 엔트리를 통해 보조기억장치에 저장되어 있는 위치를 알 수 있기 때문에 디렉터리에 속한 파일의 위치를 읽어 실행할 수도 있고, 디렉터리에 속한 다른 디렉터리의 위치를 찾아 이동할 수도 있는 것입니다.
- 디렉터리 엔트리 ‘..’ : 상위 디렉터리  
   디렉터리 엔트리 ‘.’ : 현재 디렉터리가 저장된 위치 정보

### 파일 할당

`블록(block)`

- 운영체제가 파일과 디렉터리를 읽고 쓰는 단위
- 하나의 파일이 보조기억장치에 저장될 때는 하나 이상의 블록을 할당받아 저장된다.
- 파일 시스템에 따라 파일 및 디렉터리를 어떤 번호의 블록에 어떻게 할당하는지가 달라질 수 있다.

- `연결 할당(linked allocation)`  
  : 각 블록의 일부에 다음 블록의 주소를 저장하여 각각의 블록이 다음 블록을 가리키는 형태로 할당하는 파일 시스템  
  => 파일 이름, 파일을 이루는 첫 번째 블록 주소와 파일을 이루는 블록 단위의 길이

`색인 할당(indexed allocation)`

- 파일 시스템에서 파일을 이루는 모든 블록의 주소를 `색인 블록(index block)`이라는 특별한 블록에 모아 관리하는 방식으로 할당하는 방법
- 디렉터리 엔트리에 파일 이름과 함께 색인 블록 주소가 명시됩니다.

> 색인 블록을 활용한 파일 접근 단계  
> (1) 파일 이름 → 디렉터리 엔트리에서 찾음  
> (2) 디렉터리 엔트리 → 아이노드 번호 찾음  
> (3) 아이노드 → 색인 블록의 위치를 가리킴  
> (4) 색인 블록 → 해당 파일의 실제 데이터가 저장된 블록들의 주소들을 가지고 있음  
> (5) 그 주소를 통해 → 실제 데이터 블록에 접근

- 파일 이름 → 디렉터리 엔트리

- 디렉터리는 "이름 → 아이노드 번호"를 저장하고 있는 일종의 이름-주소 사전입니다.
  예: hello.txt → 아이노드 번호 123

- 아이노드 번호를 통해 아이노드 정보 접근

  아이노드는 다음과 같은 파일의 메타데이터를 담고 있어요:

  - 파일 크기, 권한, 생성/수정 시간, `색인 블록의 위치 정보` (데이터 블록의 주소들 or 색인 구조)

- 아이노드 → 색인 정보 → 실제 데이터 블록
  아이노드에 직접 데이터 블록 주소가 들어있을 수도 있고, 파일이 크면 색인 블록(인덱스 블록)을 통해 간접적으로 데이터 블록 주소를 가리킬 수도 있어요.

### 파일 시스템

운영체제마다 각기 다른 파일 시스템을 지원하며, 같은 운영체제라도 다른 파일 시스템을 사용하거나 하나의 컴퓨터에서 여러 파일 시스템을 사용할 수 있다.

### 파티셔닝

`파티셔닝(partitioning)` : 보조기억장치의 영역을 구획하는 작업  
`파티션(partition)` : 파티셔닝되어 나누어진 하나 하나의 영역  
=> 보조기억장치는 여러 파티션으로 나눌 수 있으며, 파티션마다 다른 파일 시스템을 사용할 수 있다.

파일 시스템 방식 선택은 보조기억장치를 포매팅할 때에 결정된다.
`포매팅(formatting)` : 파일 시스템을 설정하여 어떤 방식으로 파일을 저장하고 관리할 것인지를 결정하고, 새로운 데이터를 쓸 준비를 하는 작업

### 아이노드 기반 파일 시스템

`아이노드(i-node, index-node)`

- 파일 시스템에서 각 파일마다 고유하게 존재하는 메타데이터 구조체로, 파일의 이름을 제외한 모든 정보를 저장한다.
  파일의 위치 (데이터 블록 주소), 파일 크기, 생성/수정/접근 시간, 권한 및 소유자 정보 등

- 파일을 생성하면 새로운 아이노드가 할당되고, 운영체제는 이 아이노드를 통해 파일의 데이터와 속성에 접근
- EXT4 같은 파일 시스템은 아이노드와 데이터 블록을 분리하여 관리
- 데이터 블록 공간이 남아 있어도 아이노드가 부족하면 파일을 더 이상 생성할 수 없음  
  => 아이노드가 파일 생성의 병목이 될 수 있음

### 하드 링크와 심볼릭 링크

디렉터리 A에 속한 파일 A가 있다고 가정해 보겠습니다. 디렉터리 엔트리에 파일 이름(A)과 아이노드 번호가 명시되어 있다면 해당 아이노드에 접근할 수 있고, 아이노드를 통해 파일 데이터에 접근할 수 있습니다

이러한 아이노드를 조금만 응용하면 동일한 파일 속성과 데이터 블록을 공유하는 다른 이름의 파일을 만들 수도 있고, 윈도우의 바로가기 파일처럼 파일을 가리키는 파일을 만들 수도 있습니다. 이때 전자를 하드 링크 파일, 후자를 심볼릭 링크 파일이라고 하며, 이들은 각각 하드 링크와 심볼릭 링크라는 과정을 통해 생성된 파일을 말합니다.

- `하드 링크(hard link) 파일`  
   : 원본 파일과 같은 아이노드를 공유하는 파일  
   하드 링크 파일과 원본 파일은 같은 파일 데이터를 공유하며, 하드 링크 파일을 변경하면 원본 파일도 변경된다.
  또한 하드 링크 파일이 남아있다면 원본 파일이 삭제되거나 이동되더라도 파일 데이터에 접근할 수 있습니다.
  e.g. 하드 링크 파일은 동일한 파일을 여러 이름으로 참조

- `심볼릭 링크(symbolic link) 파일`  
   : 원본 파일을 가리키는 파일
  원본 파일이 삭제되거나 이동되는 경우에는 사용이 불가능
  e.g. 복잡한 경로에 있는 파일을 바로가기 파일의 형태로 간단하게 참고

### 마운트

`마운트(mount)` : 어떤 저장장치의 파일 시스템에서 다른 저장장치의 파일 시스템으로 접근할 수 있도록 파일 시스템을 편입시키는 작업

## 추가 정리

### 전원 버튼을 누르고 부팅이 되기까지

> 컴퓨터 전원이 켜지면, CPU는 BIOS나 UEFI를 실행해 POST로 하드웨어를 점검하고, MBR에서 부트로더를 로드합니다. 부트로더는 커널을 메모리에 적재하고, 이후 커널이 실행되면서 운영체제가 시작됩니다

`부팅(Booting, 시스템 부팅)`

- 컴퓨터 전원을 켠 후 커널을 메모리에 적재하여 운영체제를 시작하는 과정

- 단계별 설명

  1.  전원 인가

      - 컴퓨터 전원을 켜면, 비휘발성 메모리(예: ROM) 에 저장된 초기 정보가 실행됨
      - CPU는 전원이 들어오면 정해진 주소를 읽음 → 이 주소에는 BIOS 또는 UEFI가 위치

  2.  `BIOS (Basic Input/Output System)`

  - 컴퓨터의 기본 입출력 시스템으로 초기 하드웨어 점검 및 부트 절차 수행
  - POST(Power-On Self Test): 하드웨어 검사
  - 이상이 없으면, 보조기억장치의 MBR(Master Boot Record) 영역을 읽음

    `+` `UEFI (Unified Extensible Firmware Interface)`

    - BIOS를 대체하는 최신 펌웨어 인터페이스
    - 대용량 디스크 지원, 빠른 부팅, 보안 기능, GUI 지원 등 향상된 기능 제공

  3.  `MBR(Master Boot Record)`

  - 보조기억장치의 첫 번째 섹터에 존재
  - 여기에는 부트스트랩(bootstrap) 또는 부트로더(boot loader) 라는 프로그램이 있음

  4.  부트로더

  - 운영체제 커널의 위치를 찾아 메모리에 적재하는 역할
  - 커널이 메모리에 올라가면 운영체제의 제어로 넘어감

### 가상 머신과 컨테이너

`가상 머신(Virtual Machine)`

- 정의
  - 소프트웨어로 구현된 가상의 컴퓨터
  - 실제 하드웨어 위에서 독립적인 운영체제(게스트 OS)를 실행
- `하이퍼바이저 (Hypervisor)`
  - 가상 머신을 생성하고 실행하는 가상화 소프트웨어
  - 하드웨어 수준에서 자원 격리 및 가상화 제공
  - 각 VM은 자신만의 운영체제를 가짐 → 높은 격리성

=> 하이퍼바이저 같은 소프트웨어가 하드웨어를 가상화하여, 각 가상 머신이 자기만의 CPU, 메모리, 디스크를 갖고 있는 것처럼 보인다.

- 단점
  - 운영체제 단위로 자원을 할당 → 무겁고 느림
  - 오버헤드 크고, 디스크/메모리 자원 소모 많음

`컨테이너(Container)`

- 정의
  - 운영체제 수준의 가상화 및 자원 격리
  - 하나의 호스트 OS 커널을 컨테이너들이 공유
  - 특정 애플리케이션 실행에 필요한 라이브러리, 코드, 파일 등의 묶음  
    == 컨테이너는 프로세스 여러 개와 필요한 파일들, 라이브러리들을 한 덩어리로 묶은 작은 가상환경이에요.  
    그냥 프로세스 한 개가 아니라, 그 프로세스가 실행되는데 필요한 환경 전체를 격리해서 운영체제 위에서 돌리는 것이죠.

=> 프로세스 단위로 자원을 격리

- 장점

  - 가볍고 빠름 (VM보다 경량), 이식성 높음(어떤 환경에서도 실행 가능), 프로세스 단위 격리하여 필요한 자원만 최소한으로 사용

- 대표 기술 : `도커(Docker)`, LXC 등

- `컨테이너 오케스트레이션(Container Orchestration)`
  - 여러 컨테이너를 자동으로 배포, 확장, 관리하는 기술
  - 대표 도구 : `쿠버네티스(Kubernetes)`
    - 컨테이너 자동 배포, 컨테이너 수 동적 조절, 컨테이너 간 네트워크 구성

<div style="height:400px"></div>

## :bulb: 면접 예상 질문

<div style="font-family: sans-serif; line-height: 1.6;">
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">공유 메모리 기반 IPC가 소켓 통신보다 빠른 이유를 설명해 보세요.</strong></summary>
    <p><strong style="color: #999;">A.</strong> 공유 메모리는 동일한 메모리 공간에 직접 접근하여 데이터를 주고받고, 마치 자신의 메모리 공간을 읽고 쓰는 것처럼 IPC가 이루어지기 때문에 빠릅니다. 이에 반해 소켓 통신은 주고받는 데이터가 커널을 통하므로 추가적인 오버헤드가 발생할 수 있어, 공유 메모리 기반 IPC보다 다소 느릴 수 있습니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">운영체제의 커널이 무엇이며, 커널이 왜 존재하는지에 대해 설명해 보세요.</strong></summary>
    <p><strong style="color: #999;">A.</strong>커널은 운영체제의 핵심 부분으로, 컴퓨터 하드웨어와 응용 프로그램 간의 중재자 역할을 합니다. 커널은 프로세스와 스레드가 올바르게 실행되도록 돕고, 이들이 CPU, 메모리, 보조기억장치 등의 하드웨어를 공정하게 할당받아 실행되도록 합니다. 또 커널은 이중 모드를 운영해 사용자 응용 프로그램이 안전하고 효율적으로 시스템 자원을 사용할 수 있도록 합니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">스레드 안전하지 않은 메서드를 동기화하지 않으면 어떤 문제가 생길 수 있나요?</strong></summary>
    <p><strong style="color: #999;">A.</strong>여러 스레드가 동시에 실행될 경우 레이스 컨디션이 발생하여 데이터의 일관성이 깨질 수 있습니다. 따라서 추가적인 동기화 도구를 적용하거나, 스레드 안전한 메서드를 사용해야 합니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">지나치게 문맥 교환이 반복되면 어떤 문제가 발생할 수 있나요?</strong></summary>
    <p><strong style="color: #999;">A.</strong> 빈번한 문맥 교환은 실제 작업보다 문맥 저장과 복구에 CPU 시간을 사용하게 되므로 효율성을 떨어뜨립니다. 또한 캐시 메모리의 데이터를 반복적으로 무효화하게 되므로 캐시 미스율이 증가하고, 캐시 미스와 문맥 교환 오버헤드로 인한 전체 시스템의 처리 속도가 저하될 수 있습니다.</p>
  </details>
    <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">운영체제란 무엇인가요?</strong></summary>
    <p><strong style="color: #999;">A.</strong>운영체제는 사용자와 하드웨어 사이에서 자원을 효율적으로 관리하고, 여러 프로그램에 공통된 서비스를 제공하는 시스템 소프트웨어입니다. 핵심 기능으로는 자원 할당 및 관리, 프로세스와 스레드 관리가 있습니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">프로세스와 스레드의 차이는 무엇인가요?</strong></summary> 
    <p><strong style="color: #999;">A.</strong>프로세스는 실행 중인 프로그램의 인스턴스이며, 독립적인 자원을 가집니다. 스레드는 프로세스 내에서 실행되는 가장 작은 단위로, 같은 프로세스의 자원을 공유합니다. 즉, 프로세스는 자원 단위, 스레드는 실행 단위입니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">시스템 콜이란 무엇이고 어떻게 작동하나요?</strong></summary> 
    <p><strong style="color: #999;">A.</strong>시스템 콜은 사용자 프로그램이 운영체제의 기능을 사용하기 위한 인터페이스입니다. 사용자 영역에서 시스템 콜을 호출하면 커널 모드로 전환되어 운영체제가 자원을 할당하거나 작업을 처리하고, 결과를 반환한 뒤 다시 사용자 모드로 돌아옵니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">문맥 교환(Context Switching)이란 무엇인가요?</strong></summary> 
    <p><strong style="color: #999;">A.</strong>문맥 교환은 CPU가 현재 실행 중인 프로세스의 상태(context)를 PCB에 저장하고, 다른 프로세스의 context를 복구하여 실행을 전환하는 과정입니다. 이 과정은 타이머 인터럽트나 입출력 대기 등에 의해 발생합니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">프로세스의 상태는 어떻게 전이되나요?</strong></summary> 
    <p><strong style="color: #999;">A.</strong>프로세스는 생성(new) → 준비(ready) → 실행(running) → 대기(blocked) → 종료(terminated) 상태를 가집니다. CPU를 받으면 실행 상태가 되고, 입출력 요청 시 대기 상태로, 시간이 초과되면 다시 준비 상태로 전환됩니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">프로세스 간 통신(IPC)의 방법은 무엇이 있나요?</strong></summary> 
    <p><strong style="color: #999;">A.</strong>대표적으로 공유 메모리, 메시지 전달(파이프, 소켓 등), 시그널 방식이 있습니다. 공유 메모리는 빠르지만 동기화가 필요하고, 메시지 전달은 속도는 느리지만 안전하며, 시그널은 비동기적 알림 방식입니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">임계 구역과 레이스 컨디션이란 무엇인가요?</strong></summary> 
    <p><strong style="color: #999;">A.</strong>임계 구역은 공유 자원에 접근하는 코드 영역이며, 레이스 컨디션은 여러 스레드가 동시에 임계 구역에 진입해 데이터 일관성이 깨지는 현상입니다. 이를 막기 위해 동기화 기법이 필요합니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">뮤텍스와 세마포의 차이는 무엇인가요?</strong></summary> 
    <p><strong style="color: #999;">A.</strong>뮤텍스는 1개의 공유 자원에 대한 상호 배제를 보장하는 락 개념이며, 세마포는 여러 개의 자원 수를 관리할 수 있는 변수 기반 동기화 기법입니다. 세마포는 이진(0/1) 또는 카운팅(여러 개) 형태로 사용됩니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">세마포의 S 값이 음수가 되는 의미는 무엇인가요?</strong></summary> 
    <p><strong style="color: #999;">A.</strong>S가 음수라는 것은 현재 대기 큐에 있는 프로세스(또는 스레드)의 개수를 의미합니다. 즉, 사용 가능한 자원은 없고, 그만큼의 프로세스가 기다리고 있다는 뜻입니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">교착 상태가 발생하는 4가지 조건은 무엇인가요?</strong></summary> 
    <p><strong style="color: #999;">A.</strong>① 상호 배제, ② 점유와 대기, ③ 비선점, ④ 원형 대기입니다. 이 네 가지 조건이 모두 만족될 때 교착 상태가 발생합니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">교착 상태를 해결하는 방법은 무엇인가요?</strong></summary> 
    <p><strong style="color: #999;">A.</strong>예방(필요조건 중 하나를 제거), 회피(은행원 알고리즘 등), 검출 후 회복(자원 회수나 프로세스 강제 종료) 등이 있습니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">스레드 안전(Thread Safety)이란 무엇인가요?</strong></summary> 
    <p><strong style="color: #999;">A.</strong>멀티스레드 환경에서 동시에 자원에 접근해도 문제가 발생하지 않도록 하는 설계입니다. 스레드 안전한 함수는 레이스 컨디션 없이 동작합니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">모니터와 조건 변수의 관계는?</strong></summary> 
    <p><strong style="color: #999;">A.</strong>모니터는 공유 자원과 이를 다루는 함수, 조건 변수로 구성됩니다. 조건 변수는 wait()와 signal()로 실행 순서를 제어하며, 모니터 내부에서 하나의 프로세스만 실행되도록 상호 배제도 보장합니다.</p>
  </details>
  <br>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">프로세스 스케줄링이 무엇인지 설명해보세요.</strong></summary> 
      <p><strong style="color: #999;">A.</strong>프로세스 스케줄링은 운영체제가 여러 프로세스들 사이에서 CPU 자원을 효율적으로 분배하는 기법입니다. 주요 목표는 CPU 사용률을 극대화하고, 응답 시간과 대기 시간을 최소화하는 것입니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">선점형 스케줄링과 비선점형 스케줄링의 차이를 설명해보세요</strong></summary> 
      <p><strong style="color: #999;">A.</strong>선점형 스케줄링은 실행 중인 프로세스를 강제로 중단시켜 다른 프로세스에 CPU를 할당할 수 있습니다. 반면, 비선점형은 현재 실행 중인 프로세스가 자발적으로 CPU를 반환할 때만 교체가 이뤄집니다. 대표적으로 Round Robin은 선점형, SJF는 비선점형입니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">가상 메모리의 개념과 장점에 대해 설명해보세요.</strong></summary> 
      <p><strong style="color: #999;">A.</strong>가상 메모리는 실제 메모리보다 큰 주소 공간을 사용하는 것처럼 프로그램을 실행할 수 있게 해주는 기법입니다. 장점으로는 메모리 효율성 향상, 멀티태스킹 지원, 프로그램 크기 제한 완화 등이 있습니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">페이지 폴트가 발생했을 때 어떤 일이 일어나는지 설명해보세요.</strong></summary> 
      <p><strong style="color: #999;">A.</strong>페이지 폴트가 발생하면, OS는 해당 페이지가 보관된 디스크에서 메모리로 데이터를 가져와야 합니다. 이 과정에서 문맥 교환이 발생하고, 실행 중인 프로세스는 일시 중단됩니다. 이로 인해 성능 저하가 발생할 수 있습니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">내부 단편화와 외부 단편화의 차이를 설명해주세요.</strong></summary> 
      <p><strong style="color: #999;">A.</strong>내부 단편화는 메모리 블록이 고정 크기로 할당될 때, 필요한 공간보다 큰 블록이 할당되어 생기는 낭비입니다. 외부 단편화는 메모리 내에 사용하지 못하는 작은 공간들이 흩어져 있어 생기는 문제입니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">스래싱이 무엇이며, 왜 발생하나요?</strong></summary> 
      <p><strong style="color: #999;">A.</strong>스래싱은 페이지 교체가 과도하게 일어나면서 프로세스가 실제 작업보다는 페이지 교체에만 시간을 소비하는 현상입니다. 주로 너무 많은 프로세스를 동시에 실행하거나, 각 프로세스에 할당된 메모리가 부족할 때 발생합니다.</p>
  </details>
  <details>
    <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">아이노드(i-node)에 대해 설명해보세요</strong></summary> 
      <p><strong style="color: #999;">A.</strong>아이노드는 파일의 메타데이터를 저장하는 구조체로, 파일의 위치, 크기, 권한, 생성 시간 등의 정보를 담고 있습니다. 파일 이름은 디렉터리 엔트리에 저장되고, 실제 내용은 아이노드가 관리합니다.</p>
  </details>
  <details>
  <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">가상 메모리가 필요한 이유는 무엇인가요?</strong></summary> 
    <p><strong style="color: #999;">A.</strong>실제 물리 메모리보다 큰 주소 공간을 제공하고, 프로세스 간 보호 및 독립성 확보, 효율적 메모리 사용을 가능하게 합니다.</p>
  </details>
  <details>
  <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">페이징과 세그멘테이션의 차이는 무엇인가요?</strong></summary> 
    <p><strong style="color: #999;">A.</strong>페이징은 메모리를 고정된 크기의 블록인 페이지 단위로 나누어 물리적 메모리를 효율적으로 사용하는 방식이고, 세그멘테이션은 코드, 데이터, 스택과 같은 의미 있는 단위로 메모리를 나누어 논리적인 구조를 반영하는 방식으로 가독성을 높일 수 있으나 외부 단편화가 발생할 수 있습니다.</p>
  </details>
  <details>
  <summary><strong style="color: #007B8F;">Q.</strong> <strong style="font-size: 1.05em;">페이지 폴트(Page Fault)가 발생했을 때 OS는 어떤 동작을 하나요?</strong></summary> 
    <p><strong style="color: #999;">A.</strong>페이지 폴트가 발생하면 CPU가 트랩을 일으켜 운영체제로 제어권이 넘어갑니다. 운영체제는 필요한 페이지를 디스크에서 메모리로 가져오고, 페이지 테이블을 갱신한 뒤, 중단되었던 프로세스를 다시 실행합니다.</p>
  </details>
</div>
